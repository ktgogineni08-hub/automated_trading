#!/usr/bin/env python3
"""
ML Data Builder
Constructs datasets for machine learning models by:
1. Fetching historical data
2. Calculating technical indicators (features)
3. Generating target labels
"""

import pandas as pd
import numpy as np
import logging
from typing import Tuple, List, Optional

from data.provider import DataProvider
from enhanced_technical_analysis import EnhancedTechnicalAnalysis
from utilities.structured_logger import get_logger

logger = get_logger(__name__)

class MLDataBuilder:
    def __init__(self, data_provider: DataProvider):
        self.dp = data_provider
        self.ta = EnhancedTechnicalAnalysis()
        
    def fetch_and_prepare_data(self, symbol: str, interval: str = "5minute", days: int = 365) -> Optional[pd.DataFrame]:
        """
        Fetch data and prepare features/labels for ML training
        """
        logger.info(f"ðŸ—ï¸ Building ML dataset for {symbol} ({interval}, {days} days)")
        
        # 1. Fetch raw data
        try:
            df = self.dp.fetch_with_retry(symbol, interval=interval, days=days)
            if df is None or df.empty:
                logger.warning(f"âŒ No data found for {symbol}. Generating SYNTHETIC data for training verification.")
                df = self._generate_synthetic_data(days=days, interval=interval)
        except Exception as e:
            logger.error(f"âŒ Error fetching data for {symbol}: {e}")
            return None
            
        # 2. Feature Engineering
        df = self._add_technical_features(df)
        
        # 3. Label Generation (Target)
        df = self._add_target_labels(df)
        
        # 4. Clean up (drop NaNs from lookback periods)
        df.dropna(inplace=True)
        
        logger.info(f"âœ… Dataset ready: {len(df)} samples, {len(df.columns)} features")
        return df

    def _add_technical_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Add technical indicators as features"""
        df = df.copy()
        
        # Price Returns
        df['log_return'] = np.log(df['close'] / df['close'].shift(1))
        
        # Volatility (Rolling Std Dev of returns)
        df['volatility_20'] = df['log_return'].rolling(window=20).std()
        
        # RSI (Vectorized)
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))
        
        # MACD
        # Note: calculate_macd returns a dict, we need to apply it row-wise or vectorize it.
        # Since TA lib is designed for single series, we'll re-implement vectorized versions here for speed
        # or use the TA lib if it supports series. The current TA lib returns scalar for last value.
        # We need rolling series. Let's implement vectorized versions here for the dataset.
        
        # Vectorized MACD
        ema12 = df['close'].ewm(span=12, adjust=False).mean()
        ema26 = df['close'].ewm(span=26, adjust=False).mean()
        df['macd_line'] = ema12 - ema26
        df['macd_signal'] = df['macd_line'].ewm(span=9, adjust=False).mean()
        df['macd_hist'] = df['macd_line'] - df['macd_signal']
        
        # Bollinger Bands (Vectorized)
        sma20 = df['close'].rolling(window=20).mean()
        std20 = df['close'].rolling(window=20).std()
        df['bb_upper'] = sma20 + (std20 * 2)
        df['bb_lower'] = sma20 - (std20 * 2)
        # Feature: Position within BB (0 to 1)
        df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])
        
        # ATR (Vectorized)
        high_low = df['high'] - df['low']
        high_close = (df['high'] - df['close'].shift()).abs()
        low_close = (df['low'] - df['close'].shift()).abs()
        ranges = pd.concat([high_low, high_close, low_close], axis=1)
        true_range = ranges.max(axis=1)
        df['atr'] = true_range.rolling(14).mean()
        # Feature: Normalized ATR (ATR / Close)
        df['atr_pct'] = df['atr'] / df['close']
        
        # Momentum (ROC)
        df['roc_10'] = df['close'].pct_change(10)
        
        return df

    def _add_target_labels(self, df: pd.DataFrame, lookahead: int = 5, threshold: float = 0.001) -> pd.DataFrame:
        """
        Generate target labels:
        1 (Up): Future return > threshold
        0 (Down/Flat): Future return <= threshold
        """
        # Calculate future return (N periods ahead)
        future_return = df['close'].shift(-lookahead) / df['close'] - 1
        
        # Create binary target
        df['target'] = (future_return > threshold).astype(int)
        
        return df

    def _generate_synthetic_data(self, days: int = 365, interval: str = "5minute") -> pd.DataFrame:
        """Generate synthetic OHLCV data for testing"""
        # Determine number of periods
        # 5min candles per day approx 75 (6.25 hours)
        periods_per_day = 75
        total_periods = days * periods_per_day
        
        dates = pd.date_range(end=pd.Timestamp.now(), periods=total_periods, freq='5min')
        
        # Random walk
        np.random.seed(42)
        returns = np.random.normal(0, 0.001, total_periods)
        price_path = 10000 * np.exp(np.cumsum(returns))
        
        df = pd.DataFrame(index=dates)
        df['close'] = price_path
        # Add noise for High/Low
        df['high'] = df['close'] * (1 + np.abs(np.random.normal(0, 0.0005, total_periods)))
        df['low'] = df['close'] * (1 - np.abs(np.random.normal(0, 0.0005, total_periods)))
        df['open'] = df['close'].shift(1).fillna(10000)
        df['volume'] = np.random.randint(1000, 100000, total_periods)
        
        return df
