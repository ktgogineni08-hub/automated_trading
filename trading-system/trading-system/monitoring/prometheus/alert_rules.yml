# Prometheus Alert Rules for Trading System
# These rules define when to trigger alerts based on metrics

groups:
  - name: trading_system_critical
    interval: 30s
    rules:
      # Service availability alerts
      - alert: ServiceDown
        expr: up{job=~"trading-system|trading-dashboard"} == 0
        for: 1m
        labels:
          severity: critical
          component: "{{ $labels.job }}"
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "{{ $labels.job }} has been down for more than 1 minute on {{ $labels.instance }}"
          
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.01
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} over the last 5 minutes"
          
      - alert: DatabaseConnectionFailed
        expr: database_connection_status == 0
        for: 1m
        labels:
          severity: critical
          component: database
        annotations:
          summary: "Database connection failure"
          description: "Cannot connect to database for more than 1 minute"
          
      - alert: RedisConnectionFailed
        expr: redis_connection_status == 0
        for: 1m
        labels:
          severity: critical
          component: redis
        annotations:
          summary: "Redis connection failure"
          description: "Cannot connect to Redis for more than 1 minute"

  - name: trading_system_performance
    interval: 1m
    rules:
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1.0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time (p95)"
          description: "95th percentile response time is {{ $value }}s"
          
      - alert: HighCPUUsage
        expr: rate(process_cpu_seconds_total[5m]) * 100 > 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage"
          description: "CPU usage is {{ $value | humanize }}% on {{ $labels.instance }}"
          
      - alert: HighMemoryUsage
        expr: (process_resident_memory_bytes / process_virtual_memory_max_bytes) * 100 > 80
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value | humanize }}% on {{ $labels.instance }}"
          
      - alert: TooManyRestarts
        expr: changes(process_start_time_seconds[15m]) > 2
        labels:
          severity: warning
        annotations:
          summary: "Service restarting frequently"
          description: "{{ $labels.job }} has restarted {{ $value }} times in the last 15 minutes"

  - name: trading_operations
    interval: 1m
    rules:
      - alert: TradeExecutionFailureRate
        expr: rate(trade_executions_total{status="failed"}[5m]) / rate(trade_executions_total[5m]) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High trade execution failure rate"
          description: "Trade failure rate is {{ $value | humanizePercentage }}"
          
      - alert: NoTradesExecuted
        expr: rate(trade_executions_total[30m]) == 0
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "No trades executed recently"
          description: "No trades have been executed in the last 30 minutes during market hours"
          
      - alert: PortfolioRiskExceeded
        expr: portfolio_risk_percentage > 2.0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Portfolio risk limit exceeded"
          description: "Portfolio risk is {{ $value }}%, exceeding the 2% limit"
          
      - alert: MaxPositionsReached
        expr: active_positions >= max_positions
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Maximum positions reached"
          description: "Number of active positions: {{ $value }}"

  - name: infrastructure
    interval: 1m
    rules:
      - alert: HighDiskUsage
        expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High disk usage"
          description: "Disk usage is {{ $value | humanize }}% on {{ $labels.instance }}"
          
      - alert: CriticalDiskUsage
        expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100 > 95
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Critical disk usage"
          description: "Disk usage is {{ $value | humanize }}% on {{ $labels.instance }} - immediate action required"
          
      - alert: HighNetworkErrors
        expr: rate(node_network_receive_errs_total[5m]) + rate(node_network_transmit_errs_total[5m]) > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High network errors"
          description: "Network errors: {{ $value }} errors/sec on {{ $labels.instance }}"
          
      - alert: ContainerOOMKilled
        expr: increase(container_oom_killed[5m]) > 0
        labels:
          severity: critical
        annotations:
          summary: "Container killed due to OOM"
          description: "Container {{ $labels.container }} was OOM killed on {{ $labels.instance }}"

  - name: database
    interval: 1m
    rules:
      - alert: DatabaseSlowQueries
        expr: rate(pg_slow_queries_total[5m]) > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High number of slow database queries"
          description: "{{ $value }} slow queries per second"
          
      - alert: DatabaseConnectionPoolExhausted
        expr: pg_stat_database_connections >= pg_settings_max_connections * 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Database connection pool nearly exhausted"
          description: "Using {{ $value }} of maximum connections"
          
      - alert: DatabaseReplicationLag
        expr: pg_replication_lag_seconds > 60
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High database replication lag"
          description: "Replication lag is {{ $value }}s"

  - name: security
    interval: 30s
    rules:
      - alert: UnauthorizedAccessAttempts
        expr: rate(http_requests_total{status="401"}[5m]) > 5
        for: 2m
        labels:
          severity: warning
          component: security
        annotations:
          summary: "High rate of unauthorized access attempts"
          description: "{{ $value }} unauthorized attempts per second"

      - alert: SuspiciousActivity
        expr: rate(security_violations_total[5m]) > 1
        for: 1m
        labels:
          severity: critical
          component: security
        annotations:
          summary: "Suspicious security activity detected"
          description: "{{ $value }} security violations per second"

      - alert: RateLimitExceeded
        expr: rate(rate_limit_exceeded_total[5m]) > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High rate of rate limit violations"
          description: "{{ $value }} rate limit violations per second"

  # ========================================
  # HIGH AVAILABILITY MONITORING
  # ========================================
  - name: high_availability
    interval: 30s
    rules:
      # PostgreSQL HA Monitoring
      - alert: PostgreSQLPrimaryDown
        expr: up{job="postgres-primary"} == 0
        for: 1m
        labels:
          severity: critical
          component: database
          ha_role: primary
        annotations:
          summary: "PostgreSQL Primary is down"
          description: "PostgreSQL primary database is unavailable. Automatic failover should occur."

      - alert: PostgreSQLNoReplicas
        expr: pg_stat_replication_clients < 1
        for: 2m
        labels:
          severity: critical
          component: database
        annotations:
          summary: "No PostgreSQL replicas connected"
          description: "No replica databases connected to primary. High availability compromised."

      - alert: PostgreSQLReplicationLagHigh
        expr: pg_replication_lag_seconds > 30
        for: 5m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "High PostgreSQL replication lag"
          description: "Replication lag is {{ $value }}s (threshold: 30s)"

      - alert: PostgreSQLReplicationLagCritical
        expr: pg_replication_lag_seconds > 300
        for: 2m
        labels:
          severity: critical
          component: database
        annotations:
          summary: "Critical PostgreSQL replication lag"
          description: "Replication lag is {{ $value }}s (threshold: 300s) - data loss risk"

      - alert: PostgreSQLReplicationBroken
        expr: pg_replication_lag_seconds > 600
        for: 1m
        labels:
          severity: critical
          component: database
        annotations:
          summary: "PostgreSQL replication appears broken"
          description: "Replication lag exceeds 10 minutes - replication may be broken"

      # Redis HA Monitoring
      - alert: RedisMasterDown
        expr: up{job="redis-master"} == 0
        for: 1m
        labels:
          severity: critical
          component: redis
          ha_role: master
        annotations:
          summary: "Redis Master is down"
          description: "Redis master is unavailable. Sentinel should promote a replica."

      - alert: RedisSentinelQuorumLost
        expr: redis_sentinel_masters_status < 2
        for: 1m
        labels:
          severity: critical
          component: redis
        annotations:
          summary: "Redis Sentinel quorum lost"
          description: "Not enough Sentinel instances ({{ $value }}) to maintain quorum. Need at least 2."

      - alert: RedisNoReplicas
        expr: redis_connected_slaves < 1
        for: 2m
        labels:
          severity: critical
          component: redis
        annotations:
          summary: "No Redis replicas connected"
          description: "No replica instances connected to master. High availability compromised."

      - alert: RedisReplicationLagHigh
        expr: redis_replication_lag_seconds > 10
        for: 5m
        labels:
          severity: warning
          component: redis
        annotations:
          summary: "High Redis replication lag"
          description: "Replication lag is {{ $value }}s"

      - alert: RedisSentinelDown
        expr: count(up{job="redis-sentinel"} == 1) < 2
        for: 2m
        labels:
          severity: critical
          component: redis
        annotations:
          summary: "Redis Sentinel instances down"
          description: "Only {{ $value }} Sentinel instances available. Need at least 2 for quorum."

      # Application Pod HA Monitoring
      - alert: TradingSystemLowReplicas
        expr: kube_deployment_status_replicas_available{deployment="trading-system"} < 2
        for: 5m
        labels:
          severity: warning
          component: application
        annotations:
          summary: "Trading System has insufficient replicas"
          description: "Only {{ $value }} replica(s) available (minimum: 2 for HA)"

      - alert: TradingSystemNoReplicas
        expr: kube_deployment_status_replicas_available{deployment="trading-system"} == 0
        for: 1m
        labels:
          severity: critical
          component: application
        annotations:
          summary: "Trading System has no available replicas"
          description: "All trading system pods are down - service completely unavailable"

      - alert: TradingSystemPodCrashLooping
        expr: rate(kube_pod_container_status_restarts_total{pod=~"trading-system-.*"}[15m]) > 0.2
        for: 5m
        labels:
          severity: warning
          component: application
        annotations:
          summary: "Trading System pod crash looping"
          description: "Pod {{ $labels.pod }} is crash looping"

      - alert: LoadBalancerNoHealthyBackends
        expr: (sum(kube_deployment_status_replicas_ready{deployment="trading-system"}) / sum(kube_deployment_spec_replicas{deployment="trading-system"})) < 0.5
        for: 3m
        labels:
          severity: critical
          component: loadbalancer
        annotations:
          summary: "Less than 50% of backends are healthy"
          description: "Only {{ $value | humanizePercentage }} of backends are healthy"

      # Cluster Health
      - alert: KubernetesNodeNotReady
        expr: kube_node_status_condition{condition="Ready",status="true"} == 0
        for: 5m
        labels:
          severity: critical
          component: kubernetes
        annotations:
          summary: "Kubernetes node not ready"
          description: "Node {{ $labels.node }} is not ready"

      # Failover Detection
      - alert: DatabaseFailoverDetected
        expr: changes(pg_replication_master_server_id[5m]) > 0
        for: 1m
        labels:
          severity: warning
          component: database
        annotations:
          summary: "PostgreSQL failover detected"
          description: "Database failover occurred - new primary elected"

      - alert: RedisFailoverDetected
        expr: changes(redis_master_server_id[5m]) > 0
        for: 1m
        labels:
          severity: warning
          component: redis
        annotations:
          summary: "Redis failover detected"
          description: "Redis failover occurred - Sentinel promoted new master"
